{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "# CTGAN and TVAE\n",
    "from sdv.tabular import CTGAN, TVAE\n",
    "# BN\n",
    "from pomegranate import *\n",
    "# Copula\n",
    "from utils import Copula_scaler, pseudo_inverse, project_samples\n",
    "# Utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Evaluation\n",
    "from utils import srmse, DWP, sampling_zeros\n",
    "from sdmetrics import single_column\n",
    "from sdv.metrics.tabular import CSTest, SVCDetection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional population synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:target at state level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Data/data\"\n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        if path == \"../Data/data/.DS_Store\":\n",
    "            continue\n",
    "        county = os.path.basename(subdir)\n",
    "        df = pd.read_csv(os.path.join(subdir, file),encoding = 'unicode_escape')\n",
    "        df[\"COUNTY\"] = county\n",
    "        dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = df.drop(df[df.COUNTY == \"data\"].index)\n",
    "del df['Unnamed: 0']\n",
    "df.to_csv(\"../Data/maryland.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"../Data/maryland.csv\")\n",
    "mapping = dict([(county, code) for code, county in enumerate(np.unique(target[\"COUNTY\"]))])\n",
    "target[\"COUNTY\"] = target[\"COUNTY\"].replace(mapping)\n",
    "target.drop([\"PUMA\"], axis=1, inplace=True)\n",
    "source = target.sample(frac=0.01)  # 0.1% PUMS \n",
    "target.drop(source.index, inplace=True)  # Remove source from target \n",
    "target.to_csv(\"../Data/exp1/target.csv\", index=False)\n",
    "source.to_csv(\"../Data/exp1/source.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"../Data/exp1/target.csv\")\n",
    "source = pd.read_csv(\"../Data/exp1/source.csv\")\n",
    "columns = target.columns\n",
    "synthetic = {}  # Will hold synthetic data\n",
    "models = [\"CTGAN\",\"CTGANCopula\",\"TVAE\",\"TVAECopula\",\"BN\", \"BNCopula\", \"Ind\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_types = {\n",
    "    \"HINCP\": {\"type\": \"categorical\"},\n",
    "    'NP': {\"type\": \"categorical\"},  # Could be numerical \n",
    "    \"AGEP\": {\"type\": 'numerical', \"subtype\": \"integer\"},\n",
    "    \"RAC1P\": {\"type\": \"categorical\"},\n",
    "    \"ESR\": {\"type\": \"categorical\"},\n",
    "    \"SEX\": {\"type\": \"categorical\"},\n",
    "    \"WIF\": {\"type\": \"categorical\"},  # Could be numerical\n",
    "    \"HUPAC\": {\"type\": \"categorical\"},\n",
    "    \"HHT\": {\"type\": \"categorical\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "ctgan_args = {\n",
    "    # \"field_names\": list(columns),\n",
    "    \"field_types\":field_types,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"generator_dim\": (256, 256),\n",
    "    \"discriminator_dim\": (256, 256),\n",
    "    \"generator_lr\": 2e-4,\n",
    "    \"generator_decay\": 1e-6,\n",
    "    \"discriminator_lr\": 2e-4,\n",
    "    \"discriminator_decay\": 1e-6,\n",
    "    \"batch_size\": 500,\n",
    "    \"discriminator_steps\": 1,\n",
    "    \"epochs\": 300,\n",
    "    \"cuda\": False\n",
    "}\n",
    "ctgan = CTGAN(**ctgan_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "ctgan.fit(source.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "ctgan_data = ctgan.sample(target.shape[0])\n",
    "synthetic[\"CTGAN\"] = ctgan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan.save(\"../Saved_Models/ctgan.pkl\")\n",
    "# CTGAN.load(\"../Saved_Models/ctgan.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN+Copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_types = {\n",
    "    \"HINCP\": {\"type\": \"categorical\"},\n",
    "    'NP': {\"type\": \"categorical\"},  # Could be numerical \n",
    "    \"AGEP\": {\"type\": 'numerical', \"subtype\": \"integer\"},\n",
    "    \"RAC1P\": {\"type\": \"categorical\"},\n",
    "    \"ESR\": {\"type\": \"categorical\"},\n",
    "    \"SEX\": {\"type\": \"categorical\"},\n",
    "    \"WIF\": {\"type\": \"categorical\"},  # Could be numerical\n",
    "    \"HUPAC\": {\"type\": \"categorical\"},\n",
    "    \"HHT\": {\"type\": \"categorical\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "ctgan_copula_args = {\n",
    "    # \"field_names\": list(columns),\n",
    "    \"field_types\":field_types,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"generator_dim\": (256, 256),\n",
    "    \"discriminator_dim\": (256, 256),\n",
    "    \"generator_lr\": 2e-4,\n",
    "    \"generator_decay\": 1e-6,\n",
    "    \"discriminator_lr\": 2e-4,\n",
    "    \"discriminator_decay\": 1e-6,\n",
    "    \"batch_size\": 500,\n",
    "    \"discriminator_steps\": 1,\n",
    "    \"epochs\": 300,\n",
    "    \"cuda\": False\n",
    "}\n",
    "ctgan_copula = CTGAN(**ctgan_copula_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n"
     ]
    }
   ],
   "source": [
    "scaler_source = Copula_scaler(source)\n",
    "scaler_target = Copula_scaler(target)\n",
    "# Copula uniform\n",
    "source_enc = scaler_source.encode(source)\n",
    "# Training and Sampling\n",
    "ctgan_copula.fit(source_enc.drop_duplicates())\n",
    "ctgan_copula_data = ctgan_copula.sample(target.shape[0])\n",
    "# Resampling trick empty here first\n",
    "\n",
    "# Pseudo inverse\n",
    "ctgan_copula_data = scaler_target.decode(ctgan_copula_data)\n",
    "synthetic[\"CTGANCopula\"] = ctgan_copula_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_source = Copula_scaler(source)\n",
    "scaler_target = Copula_scaler(target)\n",
    "# Copula uniform\n",
    "source_enc = scaler_source.encode(source)\n",
    "# Training and Sampling\n",
    "ctgan_copula.fit(source_enc.drop_duplicates())\n",
    "ctgan_copula_data = ctgan_copula.sample(target.shape[0])\n",
    "# Resampling trick empty here first\n",
    "# Pseudo inverse\n",
    "ctgan_copula_data = scaler_target.decode(ctgan_copula_data)\n",
    "synthetic[\"CTGANCopula\"] = ctgan_copula_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_copula.save(\"../Saved_Models/ctgan+copula.pkl\")\n",
    "# CTGAN.load(\"../Saved_Models/ctgan+copula.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "tvae_args = {\n",
    "    # \"field_names\": list(columns),\n",
    "    \"field_types\": field_types,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"compress_dims\": (128, 128),\n",
    "    \"decompress_dims\": (128, 128),\n",
    "    \"l2scale\": 1e-5,\n",
    "    \"batch_size\": 500,\n",
    "    \"epochs\": 300,\n",
    "    \"cuda\": False\n",
    "}\n",
    "tvae = TVAE(**tvae_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "tvae.fit(source.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "tvae_data = tvae.sample(target.shape[0])\n",
    "synthetic[\"TVAE\"] = tvae_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvae.save(\"../Saved_Models/tvae.pkl\")\n",
    "#TVAE.load(\"../Saved_Models/tvae.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVAE+Copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "tvae_copula_args = {\n",
    "    # \"field_names\": list(columns),\n",
    "    \"field_types\": field_types,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"compress_dims\": (128, 128),\n",
    "    \"decompress_dims\": (128, 128),\n",
    "    \"l2scale\": 1e-5,\n",
    "    \"batch_size\": 500,\n",
    "    \"epochs\": 300,\n",
    "    \"cuda\": False\n",
    "}\n",
    "tvae_copula = TVAE(**tvae_copula_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n"
     ]
    }
   ],
   "source": [
    "scaler_source = Copula_scaler(source)\n",
    "scaler_target = Copula_scaler(target)\n",
    "# Copula uniform\n",
    "source_enc = scaler_source.encode(source)\n",
    "# Training and Sampling\n",
    "tvae_copula.fit(source_enc.drop_duplicates())\n",
    "tvae_copula_data = tvae_copula.sample(target.shape[0])\n",
    "# Resampling trick empty here first\n",
    "# Pseudo inverse\n",
    "tvae_copula_data = scaler_target.decode(tvae_copula_data)\n",
    "synthetic[\"TVAECopula\"] = tvae_copula_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvae_copula.save(\"../Saved_Models/tvae+copula.pkl\")\n",
    "#TVAE.load(\"../Saved_Models/tvae+copula.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BayesianNetwork.from_samples(source, algorithm=\"greedy\")\n",
    "bn_data = bn.sample(n=target.shape[0], algorithm=\"rejection\")\n",
    "bn_data = pd.DataFrame(bn_data ,columns=columns)\n",
    "synthetic[\"BN\"] = bn_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN + Copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_source = Copula_scaler(source)\n",
    "scaler_target = Copula_scaler(target)\n",
    "# Copula uniform\n",
    "source_enc = scaler_source.encode(source)\n",
    "# Training and sampling\n",
    "bn_copula = BayesianNetwork.from_samples(source_enc, algorithm=\"greedy\")\n",
    "bn_copula_data = bn_copula.sample(n=target.shape[0], algorithm=\"rejection\")\n",
    "bn_copula_data = pd.DataFrame(bn_copula_data, columns=columns)\n",
    "# Resampling trick\n",
    "bn_copula_data = scaler_source.resampling_trick(bn_copula_data)\n",
    "# Pseudo inverse\n",
    "bn_copula_data = scaler_target.decode(bn_copula_data)\n",
    "synthetic[\"BNCopula\"] = bn_copula_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for IPF\n",
    "#target_ipf = target.copy()\n",
    "#source_ipf = source.copy()\n",
    "#target_ipf[\"WIF\"] += 1\n",
    "#source_ipf[\"WIF\"] += 1\n",
    "#source_ipf.to_csv(f\"../Data/exp1/ipfData/source.csv\", index=False)\n",
    "#for col in columns:\n",
    "    #unique, counts = np.unique(target_ipf[col], return_counts=True)\n",
    "    # Remove values from target that are not in source\n",
    "    #unique_source = np.unique(source_ipf[col])\n",
    "    #unique_cleaned = list(unique)\n",
    "    #counts_cleaned = list(counts)\n",
    "    #for value in unique:\n",
    "        #if value not in unique_source:\n",
    "            #idx = unique_cleaned.index(value)\n",
    "            #unique_cleaned.pop(idx)\n",
    "            #counts_cleaned.pop(idx)\n",
    "    #df = pd.DataFrame(dict(zip(unique_cleaned, counts_cleaned)), index=[0])\n",
    "    # Put 0 where data in source not in target\n",
    "    #for value in unique_source:\n",
    "        #if value not in unique:\n",
    "            #df[value] = 0\n",
    "    #df.to_csv(f\"../Data/exp1/ipfData/{col}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipf_w = pd.read_csv(\"../Data/exp1/ipfData/weights.csv\")\n",
    "#ipf_w[\"weight\"] = (ipf_w[\"weight\"]).astype(int)\n",
    "#ipf_w = ipf_w.loc[ipf_w.index.repeat(ipf_w[\"weight\"])].reset_index(drop=True)\n",
    "#ipf_data = ipf_w.drop([\"weight\", \"id\", \"geo_all\", \"avg_weight\" ,\"weight_factor\"], axis=1)\n",
    "#ipf_data[\"WIF\"] -= 1\n",
    "#synthetic[\"IPF\"] = ipf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_data = np.zeros(shape=target.shape)\n",
    "for i in range(ind_data.shape[0]):\n",
    "    for j in range(ind_data.shape[1]):\n",
    "        ind_data[i,j] = source[columns[j]].sample(1)\n",
    "\n",
    "ind_data = pd.DataFrame(ind_data, columns=columns)\n",
    "synthetic[\"Ind\"] = ind_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "for model in synthetic:\n",
    "     df = synthetic[model]\n",
    "     df.to_csv(f\"../Data/exp1/synthesis/{model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synthetic data\n",
    "for model in models:\n",
    "    synthetic[model] = pd.read_csv(f\"../Data/exp1/synthesis/{model}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csTest = CSTest(single_column.statistical.CSTest)\n",
    "svcDetection = SVCDetection()\n",
    "\n",
    "results = {}\n",
    "metadata = {\"fields\":{}}\n",
    "for col in columns:\n",
    "     metadata[\"fields\"][col] = {\"type\": \"categorical\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sdmetrics\\utils.py:62: UserWarning: Unexpected value 92.0 in synthetic data.\n",
      "  warnings.warn(f'Unexpected value {value} in synthetic data.')\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sdmetrics\\utils.py:62: UserWarning: Unexpected value 94.0 in synthetic data.\n",
      "  warnings.warn(f'Unexpected value {value} in synthetic data.')\n",
      "C:\\Users\\yzc97\\anaconda3\\lib\\site-packages\\sdmetrics\\utils.py:62: UserWarning: Unexpected value 93.0 in synthetic data.\n",
      "  warnings.warn(f'Unexpected value {value} in synthetic data.')\n"
     ]
    }
   ],
   "source": [
    "#For detection \n",
    "n=10000\n",
    "real_sample = target.sample(n=n)\n",
    "for model in synthetic:\n",
    "    results[model] = {}\n",
    "    df = synthetic[model]\n",
    "    # Chi-squared\n",
    "    cs = csTest.compute(target, df, metadata=metadata)\n",
    "    results[model][\"CS\"] = cs\n",
    "    # Detection \n",
    "    detection = svcDetection.compute(real_sample, df.sample(n=n), metadata=metadata)\n",
    "    results[model][\"detection\"] = detection\n",
    "    # SRMSE\n",
    "    for i in range(1, target.shape[1]+1):\n",
    "        tuples = list(itertools.combinations(columns, i))  # No repeated elements\n",
    "        SRMSE = 0 \n",
    "        for tuple in tuples:\n",
    "            SRMSE += srmse(\n",
    "                target.drop(list(columns.difference(tuple)), axis=1),\n",
    "                df.drop(list(columns.difference(tuple)), axis=1))\n",
    "        SRMSE /= len(tuples)\n",
    "        results[model][\"SRMSE\"+str(i)] = SRMSE\n",
    "    results[model][\"Sampling Zeros\"] = sampling_zeros(source, target, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = []\n",
    "\n",
    "for model in results:\n",
    "    if model == \"Target\": continue\n",
    "    results_df.append(\n",
    "        pd.DataFrame({i:results[model][i] for i in results[model]}, index=[model]))\n",
    "\n",
    "results_df = pd.concat(results_df)\n",
    "results_df.to_csv(\"../results/exp1/metrics.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [v for v in mapping.values()]\n",
    "keys = [k for k in mapping.keys()]\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(\n",
    "    [target[\"COUNTY\"]] + [synthetic[model][\"COUNTY\"] for model in synthetic],\n",
    "    label=[\"Target\"] + [f'{model}' for model in synthetic],\n",
    "    bins=values+[values[-1]+1]\n",
    ")\n",
    "plt.xticks(\n",
    "    values, \n",
    "    keys, \n",
    "    rotation=45\n",
    ")\n",
    "plt.xlabel(\"County\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../results/figures/countymarginals.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd88cba2c841baa4776cda69c23c1d74d3696876bfacdff47f25a3c8537e9bf6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
