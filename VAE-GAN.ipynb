{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competitive-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input,Dense,Lambda,Reshape,Conv1DTranspose, Conv1D,Flatten\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import time\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-queensland",
   "metadata": {},
   "source": [
    "# Load and Define Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HINCP</th>\n",
       "      <th>NP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WIF</th>\n",
       "      <th>HUPAC</th>\n",
       "      <th>HHT</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4504 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HINCP  NP  AGEP  RAC1P  ESR  SEX  WIF  HUPAC  HHT  PUMA  ST\n",
       "0         3   4    46      1    1    2    3      2    1  1204  24\n",
       "1         3   4    44      1    1    1    3      2    1  1204  24\n",
       "2         3   4    13      1    0    2    3      2    1  1204  24\n",
       "3         3   4     8      1    0    2    3      2    1  1204  24\n",
       "4         4   3    70      2    6    1    3      4    1  1204  24\n",
       "...     ...  ..   ...    ...  ...  ...  ...    ...  ...   ...  ..\n",
       "4499      4   2    73      1    6    2    1      4    1  1204  24\n",
       "4500      5   4    38      1    1    1    3      2    1  1204  24\n",
       "4501      5   4    36      9    1    2    3      2    1  1204  24\n",
       "4502      5   4    12      1    0    1    3      2    1  1204  24\n",
       "4503      5   4    19      9    3    1    3      2    1  1204  24\n",
       "\n",
       "[4504 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/PUMA-1204-2012to2016-5%_Treated.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ordinary-short",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HINCP</th>\n",
       "      <th>NP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WIF</th>\n",
       "      <th>HUPAC</th>\n",
       "      <th>HHT</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4504 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HINCP  NP  AGEP  RAC1P  ESR  SEX  WIF  HUPAC  HHT  PUMA  ST\n",
       "0         3   4    46      1    1    2    3      2    1  1204  24\n",
       "1         3   4    44      1    1    1    3      2    1  1204  24\n",
       "2         3   4    13      1    0    2    3      2    1  1204  24\n",
       "3         3   4     8      1    0    2    3      2    1  1204  24\n",
       "4         4   3    70      2    6    1    3      4    1  1204  24\n",
       "...     ...  ..   ...    ...  ...  ...  ...    ...  ...   ...  ..\n",
       "4499      4   2    73      1    6    2    1      4    1  1204  24\n",
       "4500      5   4    38      1    1    1    3      2    1  1204  24\n",
       "4501      5   4    36      9    1    2    3      2    1  1204  24\n",
       "4502      5   4    12      1    0    1    3      2    1  1204  24\n",
       "4503      5   4    19      9    3    1    3      2    1  1204  24\n",
       "\n",
       "[4504 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.fillna(df.mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "about-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4504, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-longitude",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demonstrated-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test=train_test_split(df,test_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "living-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax=MinMaxScaler()\n",
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "realistic-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_batchsize(X,batch_size):\n",
    "    n_size = (len(X)//batch_size)*batch_size\n",
    "    X = X[0:n_size]\n",
    "\n",
    "    return X\n",
    "batch_size = 10\n",
    "X_train = fit_batchsize(X_train, batch_size)\n",
    "X_test = fit_batchsize(X_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "undefined-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-cooking",
   "metadata": {},
   "source": [
    "# Define VAE-GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "billion-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "solid-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(latent_dim=2):\n",
    "    x = keras.Input(shape=(11,))\n",
    "    model = layers.Reshape((11,1))(x)\n",
    "    model = layers.Conv1D(12,3, activation=\"relu\", strides=1, padding=\"same\")(model)\n",
    "    model = layers.Conv1D(24,3,activation=\"relu\", strides=1, padding=\"same\")(model)\n",
    "    model = layers.Flatten()(model)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(model)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(model)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    meansigma = keras.Model(x, [z_mean, z_log_var, z])\n",
    "    return meansigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "urban-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decgen(latent_dim=2):\n",
    "    x = keras.Input(shape=(latent_dim,))\n",
    "    model = layers.Dense(11 * 24, activation=\"relu\")(x)\n",
    "    model = layers.Reshape((11, 24))(model)\n",
    "    model = layers.Conv1DTranspose(24, 3, activation=\"relu\", strides=1, padding=\"same\")(model)\n",
    "    model = layers.Conv1DTranspose(12, 3, activation=\"relu\", strides=1, padding=\"same\")(model)\n",
    "    model = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(model)\n",
    "    model = layers.Reshape((11,))(model)\n",
    "    model = keras.Model(x, model)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "paperback-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    x = keras.Input(shape=(11,))\n",
    "    model = layers.Reshape((11,1))(x)\n",
    "    model = layers.Conv1D(12,3, activation=\"relu\", strides=1, padding=\"same\")(model)\n",
    "    model = layers.Conv1D(24,3,activation=\"relu\", strides=1, padding=\"same\")(model)\n",
    "    model = layers.Flatten()(model)\n",
    "    model = layers.Dense(1, activation=\"sigmoid\")(model)\n",
    "    output= keras.Model(x, model)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suspended-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decgen(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 11\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "upper-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    \n",
    "  # initialize models with latent dimensions\n",
    "  def __init__(self, disc, gen, latent_dim=2):\n",
    "    super(GAN, self).__init__()\n",
    "    self.discriminator = disc\n",
    "    self.generator = gen\n",
    "    self.latent_dim = latent_dim\n",
    "  \n",
    "  # compile with optimizers and loss function\n",
    "  def compile(self, optD, optG, loss_fn):\n",
    "    super(GAN, self).compile()\n",
    "    self.optD = optD\n",
    "    self.optG = optG\n",
    "    self.loss_fn = loss_fn\n",
    "    \n",
    "  # custom training function\n",
    "  def train_step(self, real_data):\n",
    "    if isinstance(real_data, tuple):\n",
    "      real_data = real_data[0]\n",
    "    \n",
    "    # get current batch size\n",
    "    bs = tf.shape(real_data)[0]\n",
    "    z = tf.random.normal(shape=(bs, self.latent_dim))\n",
    "    fake_data = self.generator(z)\n",
    "    \n",
    "    # combine real and fake images in a single vector along with their labels\n",
    "    combined_data = tf.concat([real_data, fake_data], axis=0)\n",
    "    labels = tf.concat([tf.ones((bs, 1)), tf.zeros((bs, 1))], axis=0)\n",
    "    \n",
    "    # train your discriminator\n",
    "    with tf.GradientTape() as tape:\n",
    "      preds = self.discriminator(combined_data)\n",
    "      d_loss = self.loss_fn(labels, preds)\n",
    "      grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "      self.optD.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "    \n",
    "    # misleading labels for generator\n",
    "    misleading_labels = tf.ones((bs, 1))\n",
    "    z = tf.random.normal(shape=(bs, self.latent_dim))\n",
    "    \n",
    "    # train your generator\n",
    "    with tf.GradientTape() as tape:\n",
    "      fake_preds = self.discriminator(self.generator(z))\n",
    "      g_loss = self.loss_fn(misleading_labels, fake_preds)\n",
    "      grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "      self.optG.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "    return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "# create GAN model using already built D and G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "still-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=encoder()\n",
    "decgen=decgen()\n",
    "vae = VAE(encoder, decgen)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "discriminator = discriminator()\n",
    "gan = GAN(discriminator, decgen)\n",
    "# compile your model with loss and optimizers\n",
    "gan.compile(\n",
    "    keras.optimizers.Adam(),\n",
    "    keras.optimizers.Adam(),\n",
    "    keras.losses.BinaryCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statewide-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "135/135 [==============================] - 1s 3ms/step - loss: 5.9200 - reconstruction_loss: 5.8969 - kl_loss: 0.0231\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.9877 - reconstruction_loss: 4.7042 - kl_loss: 0.2835\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.8554 - reconstruction_loss: 4.3708 - kl_loss: 0.4847\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.8079 - reconstruction_loss: 4.2636 - kl_loss: 0.5443\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.7704 - reconstruction_loss: 4.1763 - kl_loss: 0.5941\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.7637 - reconstruction_loss: 4.1216 - kl_loss: 0.6421\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.7408 - reconstruction_loss: 4.0539 - kl_loss: 0.6869\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6986 - reconstruction_loss: 3.9912 - kl_loss: 0.7074\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6784 - reconstruction_loss: 3.9446 - kl_loss: 0.7338\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6740 - reconstruction_loss: 3.9152 - kl_loss: 0.7588\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6547 - reconstruction_loss: 3.8788 - kl_loss: 0.7758\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6565 - reconstruction_loss: 3.8528 - kl_loss: 0.8037\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6563 - reconstruction_loss: 3.8443 - kl_loss: 0.8120\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6381 - reconstruction_loss: 3.8349 - kl_loss: 0.8033\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6393 - reconstruction_loss: 3.8303 - kl_loss: 0.8090\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6419 - reconstruction_loss: 3.8220 - kl_loss: 0.8199\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6301 - reconstruction_loss: 3.8144 - kl_loss: 0.8156\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6197 - reconstruction_loss: 3.8122 - kl_loss: 0.8075\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 4.6300 - reconstruction_loss: 3.7969 - kl_loss: 0.8331\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 4.6010 - reconstruction_loss: 3.7850 - kl_loss: 0.8159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5b988e848>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(X_train,X_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technological-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "135/135 [==============================] - 1s 3ms/step - d_loss: 0.6955 - g_loss: 0.6690\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6790 - g_loss: 0.7258\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6283 - g_loss: 0.7729\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6455 - g_loss: 1.0741\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6080 - g_loss: 0.8456\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.5620 - g_loss: 0.8409\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.5434 - g_loss: 1.4089\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.7376 - g_loss: 0.7166\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6650 - g_loss: 0.7606\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6553 - g_loss: 0.7725\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6336 - g_loss: 0.7778\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.5403 - g_loss: 1.1680\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6887 - g_loss: 0.7580\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6294 - g_loss: 0.8397\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.5683 - g_loss: 0.9616\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.5877 - g_loss: 0.9527\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6763 - g_loss: 0.8091\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.7014 - g_loss: 0.7520\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6446 - g_loss: 0.8305\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 3ms/step - d_loss: 0.6508 - g_loss: 0.8204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5babb7488>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(X_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "secure-fairy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4300, 11), dtype=float32, numpy=\n",
       "array([[9.9473369e-01, 1.3376576e-01, 1.0022947e-01, ..., 1.0000000e+00,\n",
       "        1.8294677e-11, 3.6588706e-13],\n",
       "       [8.5846269e-01, 6.2751102e-01, 9.8416150e-02, ..., 1.8339843e-02,\n",
       "        1.1907995e-02, 3.4481149e-05],\n",
       "       [9.3095660e-01, 3.7155163e-01, 1.7663574e-01, ..., 9.8069745e-01,\n",
       "        5.6144595e-04, 3.6842587e-06],\n",
       "       ...,\n",
       "       [9.6666193e-01, 1.8747780e-01, 3.3370593e-01, ..., 9.3422392e-07,\n",
       "        3.7485026e-10, 5.7782423e-10],\n",
       "       [9.8784173e-01, 1.8430734e-01, 1.4304379e-01, ..., 9.9999809e-01,\n",
       "        7.7912743e-09, 1.5486953e-10],\n",
       "       [9.5766485e-01, 3.1954810e-01, 3.7307432e-01, ..., 4.4721099e-05,\n",
       "        9.6934812e-08, 4.5855884e-08]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean, z_log_var, z = encoder(X_train)\n",
    "generated_data=decgen(z)\n",
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stainless-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[8.9940596e-01 4.5875603e-01 1.7085603e-01 ... 7.6712221e-02\n",
      "  3.5344362e-03 1.6990572e-05]\n",
      " [9.0090966e-01 4.5791599e-01 1.7774639e-01 ... 4.9769521e-02\n",
      "  1.9700527e-03 1.2578583e-05]\n",
      " [9.3519294e-01 3.7960297e-01 2.1795657e-01 ... 2.2873238e-01\n",
      "  1.8861890e-04 2.0930961e-06]\n",
      " ...\n",
      " [5.9778768e-01 4.5255604e-01 2.1429482e-01 ... 1.9189927e-05\n",
      "  3.9558709e-03 1.6605140e-05]\n",
      " [9.4908142e-01 3.2546484e-01 1.6812876e-01 ... 9.9931812e-01\n",
      "  4.8176626e-05 7.9916481e-07]\n",
      " [9.1406256e-01 4.4053292e-01 2.0403141e-01 ... 1.2953788e-02\n",
      "  3.3870339e-04 4.5991305e-06]], shape=(20200, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = encoder(X_test)\n",
    "generated_data=decgen(z)\n",
    "X_test=tf.convert_to_tensor(X_test)\n",
    "\n",
    "fin_X_test=X_test\n",
    "\n",
    "for i in range(100):\n",
    "    z_mean, z_log_var, z = encoder(X_test)\n",
    "    generated_data=tf.concat([generated_data,decgen(z)],0)\n",
    "\n",
    "print(generated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lasting-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.59762383e+00, 4.75253618e+00, 1.60604667e+01, ...,\n",
       "        1.15342444e+00, 1.20400353e+03, 2.40000170e+01],\n",
       "       [5.60363865e+00, 4.74749595e+00, 1.67081602e+01, ...,\n",
       "        1.09953904e+00, 1.20400197e+03, 2.40000126e+01],\n",
       "       [5.74077177e+00, 4.27761781e+00, 2.04879178e+01, ...,\n",
       "        1.45746475e+00, 1.20400019e+03, 2.40000021e+01],\n",
       "       ...,\n",
       "       [4.39115071e+00, 4.71533626e+00, 2.01437132e+01, ...,\n",
       "        1.00003838e+00, 1.20400396e+03, 2.40000166e+01],\n",
       "       [5.79632568e+00, 3.95278907e+00, 1.58041033e+01, ...,\n",
       "        2.99863625e+00, 1.20400005e+03, 2.40000008e+01],\n",
       "       [5.65625024e+00, 4.64319754e+00, 1.91789523e+01, ...,\n",
       "        1.02590758e+00, 1.20400034e+03, 2.40000046e+01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data=minmax.inverse_transform(generated_data)\n",
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "complimentary-quarter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.000e+00, 5.000e+00, 1.600e+01, ..., 1.000e+00, 1.204e+03,\n",
       "        2.400e+01],\n",
       "       [6.000e+00, 5.000e+00, 1.700e+01, ..., 1.000e+00, 1.204e+03,\n",
       "        2.400e+01],\n",
       "       [6.000e+00, 4.000e+00, 2.000e+01, ..., 1.000e+00, 1.204e+03,\n",
       "        2.400e+01],\n",
       "       ...,\n",
       "       [4.000e+00, 5.000e+00, 2.000e+01, ..., 1.000e+00, 1.204e+03,\n",
       "        2.400e+01],\n",
       "       [6.000e+00, 4.000e+00, 1.600e+01, ..., 3.000e+00, 1.204e+03,\n",
       "        2.400e+01],\n",
       "       [6.000e+00, 5.000e+00, 1.900e+01, ..., 1.000e+00, 1.204e+03,\n",
       "        2.400e+01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data=np.round(generated_data)\n",
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "present-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data=pd.DataFrame(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hourly-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data.to_csv('VAE-GAN reconstruction PUMA==1204.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-pickup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
